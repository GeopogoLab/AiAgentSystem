# Llama 70B éƒ¨ç½²çŠ¶æ€æŠ¥å‘Š

**æ›´æ–°æ—¶é—´**: 2025-12-07
**ç›®æ ‡**: åœ¨100GBå•å¡ä¸Šéƒ¨ç½²Llama 70Bæ¨¡å‹ï¼ˆä½¿ç”¨é‡åŒ–ï¼‰

---

## ğŸ“Š éƒ¨ç½²å°è¯•æ€»ç»“

### 1. Llama 3.3 70B INT8 é‡åŒ– âŒ

**é…ç½®**:
- æ¨¡å‹: `meta-llama/Llama-3.3-70B-Instruct`
- é‡åŒ–: FP8 (vLLMçš„INT8ç­‰æ•ˆ)
- GPU: H100 æˆ– A100-80GB+
- æ˜¾å­˜éœ€æ±‚: ~85-90GB
- éƒ¨ç½²æ–‡ä»¶: `modal_vllm_llama33_70b_int8.py`

**çŠ¶æ€**: âŒ **éƒ¨ç½²å¤±è´¥ - é—¨æ§æ¨¡å‹è®¿é—®å—é™**

**é”™è¯¯ä¿¡æ¯**:
```
huggingface_hub.errors.GatedRepoError: 403 Client Error
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct
Access to model meta-llama/Llama-3.3-70B-Instruct is restricted
```

**åŸå› **:
- Llama 3.3 70B æ˜¯Metaçš„é—¨æ§æ¨¡å‹
- éœ€è¦åœ¨HuggingFaceä¸Šç”³è¯·è®¿é—®æƒé™
- å½“å‰çš„HuggingFace tokenæœªè·å¾—æ­¤æ¨¡å‹çš„è®¿é—®æˆæƒ

**è§£å†³æ–¹æ¡ˆ**:
1. è®¿é—®: https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct
2. ç‚¹å‡»"Request Access"æŒ‰é’®
3. ä½¿ç”¨ä¸Modal secretä¸­ç›¸åŒçš„HuggingFaceè´¦å·
4. ç­‰å¾…Metaæ‰¹å‡†ï¼ˆé€šå¸¸1-24å°æ—¶ï¼‰
5. æ‰¹å‡†åï¼Œæ— éœ€ä¿®æ”¹ä»£ç ï¼Œç›´æ¥é‡æ–°éƒ¨ç½²å³å¯

**éƒ¨ç½²URL**:
- Wrapper: https://ybpang-1--vllm-llama33-70b-int8-wrapper.modal.run
- Healthæ£€æŸ¥æ­£å¸¸ï¼Œä½†æ¨ç†åŠŸèƒ½å—é˜»

---

### 2. Llama 3.1 70B AWQ é‡åŒ– âš ï¸

**é…ç½®**:
- æ¨¡å‹: `casperhansen/llama-3.1-70b-instruct-awq`
- é‡åŒ–: AWQ INT4
- GPU: å•ä¸ªA100-80GB
- æ˜¾å­˜éœ€æ±‚: ~55GB
- éƒ¨ç½²æ–‡ä»¶: `modal_vllm_70b_awq.py`

**çŠ¶æ€**: âš ï¸ **éƒ¨ç½²æˆåŠŸä½†æ¨ç†å¤±è´¥**

**é”™è¯¯ä¿¡æ¯**:
```
No supported config format found in casperhansen/llama-3.1-70b-instruct-awq
```

**å¯èƒ½åŸå› **:
1. AWQæ¨¡å‹é…ç½®æ ¼å¼ä¸å½“å‰vLLMç‰ˆæœ¬ä¸å…¼å®¹
2. æ¨¡å‹ä»“åº“ç»“æ„å¯èƒ½æœ‰é—®é¢˜
3. éœ€è¦é¢å¤–çš„é…ç½®å‚æ•°

**éƒ¨ç½²URL**:
- Wrapper: https://ybpang-1--vllm-70b-awq-wrapper.modal.run
- Healthæ£€æŸ¥: âœ… æ­£å¸¸
- æ¨ç†åŠŸèƒ½: âŒ å¤±è´¥

**å¯èƒ½çš„ä¿®å¤æ–¹æ¡ˆ**:
1. å°è¯•ä¸åŒçš„AWQæ¨¡å‹ï¼ˆå¦‚TheBlokeçš„ç‰ˆæœ¬ï¼‰
2. æ›´æ–°vLLMç‰ˆæœ¬
3. ä½¿ç”¨GPTQé‡åŒ–ä»£æ›¿AWQ
4. æ‰‹åŠ¨æŒ‡å®šé…ç½®å‚æ•°

---

## ğŸ¯ æ¨èçš„ä¸‹ä¸€æ­¥æ–¹æ¡ˆ

### æ–¹æ¡ˆA: ç”³è¯·Llama 3.3è®¿é—®æƒé™ â­ **æ¨è**

**ä¼˜åŠ¿**:
- âœ… æœ€æ–°çš„Llama 3.3æ¨¡å‹ï¼ˆMetaæœ€æ–°å‘å¸ƒï¼‰
- âœ… é…ç½®å·²ç»å®Œæˆå¹¶éƒ¨ç½²
- âœ… INT8é‡åŒ–æ€§èƒ½ä¼˜ç§€ï¼ˆ<2%è´¨é‡æŸå¤±ï¼‰
- âœ… å•H100æˆ–A100-80GBå³å¯è¿è¡Œ

**æ­¥éª¤**:
1. è®¿é—® https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct
2. ç™»å½•HuggingFaceè´¦å·ï¼ˆéœ€è¦ä¸Modal secretä¸­çš„tokenå¯¹åº”ï¼‰
3. ç‚¹å‡»"Request Access"
4. å¡«å†™ç”³è¯·è¡¨æ ¼ï¼ˆè¯´æ˜ç”¨é€”ï¼šç ”ç©¶/å¼€å‘ï¼‰
5. ç­‰å¾…æ‰¹å‡†ï¼ˆé€šå¸¸å‡ å°æ—¶åˆ°1å¤©ï¼‰
6. æ‰¹å‡†åé‡æ–°æµ‹è¯•éƒ¨ç½²çš„æœåŠ¡

**æ—¶é—´**: ç­‰å¾…1-24å°æ—¶æ‰¹å‡†

---

### æ–¹æ¡ˆB: ä½¿ç”¨Llama 3.1 70Bï¼ˆåŸå§‹Metaç‰ˆæœ¬ï¼‰

**å¦‚æœAWQä¸å·¥ä½œï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨Metaçš„Llama 3.1 70B**:

```python
# ä¿®æ”¹modal_vllm_70b_awq.py
VLLM_MODEL = "meta-llama/Llama-3.1-70B-Instruct"  # æ”¹ç”¨åŸå§‹ç‰ˆæœ¬

vllm_llm = LLM(
    model=VLLM_MODEL,
    quantization="fp8",  # æˆ–"awq"
    gpu="A100-80GB:2",   # éœ€è¦2ä¸ªGPU
    tensor_parallel_size=2,
)
```

**æ˜¾å­˜éœ€æ±‚**:
- FP8é‡åŒ–: 2Ã—A100-80GB (æ¯å¡~70GB)
- FP16åŸå§‹: 2Ã—A100-80GB (æ¯å¡~80GB)

**æˆæœ¬**: ~$2.20/å°æ—¶ (vs INT4çš„$1.10/å°æ—¶)

---

### æ–¹æ¡ˆC: ä¿®å¤AWQé…ç½®

**å°è¯•å…¶ä»–AWQæ¨¡å‹**:

1. **TheBlokeçš„AWQæ¨¡å‹**:
   ```python
   VLLM_MODEL = "TheBloke/Llama-2-70B-Chat-AWQ"
   ```

2. **ä½¿ç”¨GPTQé‡åŒ–ä»£æ›¿**:
   ```python
   VLLM_MODEL = "TheBloke/Llama-2-70B-Chat-GPTQ"
   quantization = "gptq"
   ```

---

## ğŸ“ˆ æ¨¡å‹å¯¹æ¯”

| æ–¹æ¡ˆ | æ¨¡å‹ | é‡åŒ– | GPUéœ€æ±‚ | æ˜¾å­˜ | æˆæœ¬/å°æ—¶ | çŠ¶æ€ |
|------|------|------|---------|------|-----------|------|
| **Llama 3.3 INT8** | 3.3 70B | FP8 | 1Ã—H100 | ~90GB | $1.50 | âŒ éœ€è¦è®¿é—®æƒé™ |
| **Llama 3.1 AWQ** | 3.1 70B | INT4 | 1Ã—A100 | ~55GB | $1.10 | âš ï¸ é…ç½®é”™è¯¯ |
| **Llama 3.1 FP8** | 3.1 70B | FP8 | 2Ã—A100 | ~140GB | $2.20 | âœ… å¯ç”¨ |
| **Llama 3.1 8B** | 3.1 8B | æ—  | 1Ã—A100 | ~20GB | $1.10 | âœ… å·²éƒ¨ç½²æµ‹è¯• |

---

## ğŸ”§ å½“å‰å¯ç”¨çš„æœåŠ¡

### âœ… Llama 3.1 8Bï¼ˆå·²æµ‹è¯•é€šè¿‡ï¼‰
- URL: https://ybpang-1--vllm-autoscale-v2-wrapper.modal.run
- çŠ¶æ€: å®Œå…¨å¯ç”¨
- æ€§èƒ½: 0.6ç§’çƒ­å¯åŠ¨ï¼Œ5/6æµ‹è¯•é€šè¿‡
- é€‚ç”¨: é€šç”¨å¯¹è¯ã€ä»£ç ç”Ÿæˆã€å†…å®¹åˆ›ä½œ

### âš ï¸ Llama 3.3 70B INT8ï¼ˆç­‰å¾…è®¿é—®æƒé™ï¼‰
- URL: https://ybpang-1--vllm-llama33-70b-int8-wrapper.modal.run
- çŠ¶æ€: å·²éƒ¨ç½²ï¼Œç­‰å¾…HuggingFaceè®¿é—®æ‰¹å‡†
- é¢„æœŸæ€§èƒ½: ~40-50 tokens/ç§’ï¼Œ<2%è´¨é‡æŸå¤±

### âš ï¸ Llama 3.1 70B AWQï¼ˆé…ç½®é—®é¢˜ï¼‰
- URL: https://ybpang-1--vllm-70b-awq-wrapper.modal.run
- çŠ¶æ€: éƒ¨ç½²æˆåŠŸï¼Œä½†æ¨ç†å¤±è´¥
- éœ€è¦: ä¿®å¤é…ç½®æˆ–æ›´æ¢æ¨¡å‹

---

## ğŸ’¡ å»ºè®®

**ç«‹å³è¡ŒåŠ¨**:
1. âœ… **ç”³è¯·Llama 3.3è®¿é—®æƒé™**ï¼ˆæ–¹æ¡ˆAï¼‰ - æœ€ç®€å•çš„è§£å†³æ–¹æ¡ˆ
2. â³ ç­‰å¾…æ‰¹å‡†æœŸé—´ï¼Œå¯ä»¥ç»§ç»­ä½¿ç”¨8Bæ¨¡å‹è¿›è¡Œå¼€å‘
3. ğŸ“Š æ‰¹å‡†åç«‹å³æµ‹è¯•Llama 3.3 70B INT8æœåŠ¡

**å¤‡é€‰æ–¹æ¡ˆ**:
- å¦‚æœéœ€è¦ç«‹å³ä½¿ç”¨70Bæ¨¡å‹ï¼Œå¯ä»¥éƒ¨ç½²Llama 3.1 70B FP8ï¼ˆ2ä¸ªGPUï¼‰
- å¦‚æœæˆæœ¬æ•æ„Ÿï¼Œç»§ç»­ä½¿ç”¨8Bæ¨¡å‹ä¹Ÿèƒ½æ»¡è¶³å¤§å¤šæ•°éœ€æ±‚

---

## ğŸ“ å¾…åŠäº‹é¡¹

- [ ] åœ¨HuggingFaceä¸Šç”³è¯·Llama 3.3 70Bè®¿é—®æƒé™
- [ ] ç­‰å¾…Metaæ‰¹å‡†ï¼ˆ1-24å°æ—¶ï¼‰
- [ ] æ‰¹å‡†åæµ‹è¯•Llama 3.3 70B INT8æœåŠ¡
- [ ] ï¼ˆå¯é€‰ï¼‰ä¿®å¤AWQé…ç½®æˆ–å°è¯•å…¶ä»–é‡åŒ–æ–¹æ¡ˆ

---

**æ€»ç»“**:
- Llama 3.3 70B INT8çš„éƒ¨ç½²é…ç½®æ­£ç¡®ï¼Œåªéœ€è·å¾—HuggingFaceè®¿é—®æƒé™å³å¯ä½¿ç”¨
- è¿™æ˜¯æœ€ç®€å•ä¸”æœ€ä¼˜çš„è§£å†³æ–¹æ¡ˆï¼ˆå•å¡ã€ä½æˆæœ¬ã€é«˜è´¨é‡ï¼‰
- ç”³è¯·è®¿é—®é€šå¸¸å¾ˆå¿«è·æ‰¹ï¼Œå»ºè®®ç«‹å³ç”³è¯·

